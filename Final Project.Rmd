---
title: "Final Project"
subtitle: "UVA SEAS Salary and Gender" 
author: "Megan Lin, James Powell, Eva Mustafic"
date: "5/5/2021"
output: 
  html_document:
    theme: spacelab
    toc: true
    toc_float : true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, message = FALSE)
library(class)
library(caret)
library(e1071) 
library(tidytext)
library(dplyr)
library(readr)
library(knitr)
library(ggplot2)
library(tidyverse)
library(C50)
library(mlbench)
library(rattle)
library(rpart.plot)
library(rio)
library(plyr)
library(dplyr)
library(tidyverse)
library(rpart)
library(psych)
library(pROC)
```


## Question of Interest

For our analysis we were interested to see if there was a difference between male and female when it comes to salaries at UVA. In order to explore that, we started of with a question:

1. Is gender a top determining factor within the top N% of faculty at UVA?

For that purposes we decide to use KNN model and explore this question further. But as we will explain later, we did not have many answers to that question, so we were determined to change it. Or follow up question was:

2. Can we predict the gender based on salary (as well as other variables)?

For that purposes we decided to use Decision Tree model and as we will explain later, had more success in explaining what role does gender play at UVA faculty positions. 




## Data 

The data we used to do our initial background research was the {r} [Cavalier Daily's 2020 Faculty Salaries] (https://www.cavalierdaily.com/page/faculty-salary-2020) . The dataset used in our evaluation was a smaller, more specific dataset on UVA's School of Engineering & Applied Science Faculty. However, the information provided within this dataset only included the faculty's name, ID, department, and tenure (Tenured vs. On Track vs. AGF). 

The Cavalier Daily's dataset was used to merge the salary into the dataset based on name. However, some names were not matched up because some faculty members use nicknames or had a change in last name likely due to getting married recently. Faculty members who were not found in the Cavalier Daily were manually double checked and their salaries were added if the department, role, and first name or last name matched up.

Multiple online name and gender dictionaries were used in conjunction with a Python program to determine the gender of the faculty member based on their first name since this information was not readily available. If any of the dictionaries labeled the name as indeterminately female/male (aka a gender-neutral name like Alex), the faculty member was given a ? for gender even if another gender dictionary gave it a determinate female or male labeling. If the gender was not found in any of the datasets, it was given a NA for gender.

In our evaluation, we will only be looking at faculty members who have a determine female or male name.




### Reading in the Data

The data has previously been merged and cleaned using Python, but we are going to make sure all of the rows with incomplete data are filtered out. Specifically, we will be filtering out employees with a gender the Python program was unable to find in any existing gender-name dictionaries or was deemed to be a gender-neutral name like Alex.

```{r, echo=FALSE, include=FALSE, warning=FALSE}

data <- read.csv("SEAS_cleandata.csv")
data <- subset(data, Gender %in% c("F", "M"))

#levels(data$Gender)<- c(NA, 0,1)
#data$Gender <- as.numeric(as.character(data$Gender))
vars <- c('Department', 'Position', 'Tenure','Gender', 'Salary')
data_clean <- data[,(names(data) %in% vars)]
data_clean$Salary <- as.numeric(gsub("[\\$,]", "", data_clean$Salary))

sapply(data_clean, class) 
```

```{r}
kable(head(data))
```

### Female vs. Male Split
To determine the split, we had to determine the ratio of female to total, and based on that, we can deduce the percent of male entries, and the percentage of both. To do this we created the function ad_split, which prints the ratio of female to total entries and ran it on the clean salary dataset. The split between female to male is 22 percent to 78 percent within the School of Engineering, respectively.

```{r echo=FALSE, include = FALSE, message = FALSE}
# Determine the split between female and male, then calculate the base rate
ad_split <- function(dat){
  female <- filter(dat, Gender == 'F')
  n_comm <- nrow(female)
  n_noncomm <- nrow(dat) - nrow(female)
  n_total <- nrow(dat)
  n_comm/n_total
}
ad_split(data)
#There is a 22/78 split
```

### Cleaning the Data

To filter out the vars, we create a list of the vars names and saved the dataset over itself without the columns in the vars variable. 
```{r echo=FALSE, message = FALSE}
# We drop all columns that do not contain relevant data
vars <- c('Department', 'Position', 'Tenure', 'Gender', 'Salary')
data_clean <- data[,(names(data) %in% vars)]
data_clean$Department <- as.numeric(as.factor(data_clean$Department))
data_clean$Position <- as.numeric(as.factor(data_clean$Position))
data_clean$Tenure <- as.numeric(as.factor(data_clean$Tenure))
data_clean$Gender <- as.numeric(as.factor(data_clean$Gender))
data_clean$Salary <- as.numeric(gsub("[\\$,]", "", data_clean$Salary))

sapply(data_clean, class) 
```

## Approach #1: KNN

James if you can explain how this would have worked here even though its not going to work-- worthwhile to give more info since we already did the work for it
Afterwards, we just simply had to run the function cor(), to discover how each column was related to each other to. We want to check if there are any highly correlated variables and remove them so as to not skew our KNN. We used a threshold of 0.7 to determine if something was too highly correlated.

### Correlation Between Variables
```{r}
# Before we run kNN, sometimes it's good to check to make sure that our variables are not highly correlated. Use the cor() function on data_clean, label it 'correlations', and view the data, because kNN doesn't work well in high dimensions. 
correlations <- cor(data_clean)
```

None of the variable are too highly correlated so we will leave these all in. We will note that Tenure and Salary has a correlation of 0.6 so we will keep an eye out for it. 

The good thing we can see here though is that Gender & Salary only have a correlation of 0.15 which is low and indicated that there isn't a glass ceiling we should be worried about if we are looking only at gender. However, there are more things that determine if there is indeed a glass ceiling-- specifically if these employees we are comparing are indeed doing "the same job".

### Generate Training and Testing Sets

```{r echo=FALSE, include = FALSE, message = FALSE}
# Use the index to generate a train and test sets, then check the row counts to be safe. 
# Check the composition of labels in the data set. 

# Let's split the data into a training and a test set.
# Sample 80% of our know data as training and 20% as test.
set.seed(1982)
train_rows <- sample(1:nrow(data_clean),
                              round(0.8 * nrow(data_clean), 0),
                              replace = FALSE)#<- don't replace the numbers


train_knn <- data_clean[train_rows, ] #<- select the rows identified
test_knn <- data_clean[-train_rows, ]  #<- select the rows that weren't identified 
```

### Data Sets {.tabset}

#### Training Data
```{r }
kable(head(train_knn))
```

#### Testing Data
```{r }
kable(head(test_knn))
```

### Choosing the Best K
```{r echo=FALSE, include = FALSE, message = FALSE}
# Run the "chooseK" function to find the perfect K, while using sapply() function on chooseK() to test k from 1 to 21 (only selecting the odd numbers)
labels<- colnames(data_clean)

chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  use.all = TRUE)       #<- control ties between class assignments#   If true, all distances equal to the kth largest are included
  conf_mat = table(class_knn, val_class)
  
  # Calculate the accuracy#could change this to Sensitivity 
  accu = sum(conf_mat[row(conf_mat) == col(conf_mat)]) / sum(conf_mat)                         
  cbind(k = k, accuracy = accu)
}

knn_diff_k_com <- sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = train_knn[labels],
                                             val_set = test_knn[labels],
                                             train_class = train_knn[, "Salary"],
                                             val_class = test_knn[, "Salary"]))
# Create a dataframe so we can visualize the difference in accuracy based on K, convert the matrix to a dataframe
trans_knn_diff_k_com<-as.data.frame(t(as.matrix(knn_diff_k_com)))

colnames(trans_knn_diff_k_com)<-c("K", "Accuracy")
trans_knn_diff_k_com <- trans_knn_diff_k_com[order(trans_knn_diff_k_com$Accuracy),] 
trans_knn_diff_k_com
```

Unfortunately, we see that there are no good number of splits if we use KNN so instead we can look at which variable is most important using a decision tree!

## Approach #2: Decision Trees

We're going to switch over to using a decision tree to see if we can accurately predict an employee's salary based on a combination of 1-3 factors from their gender, department, and tenure.

### Cleaning the Data

To filter out the vars, we create a list of the vars names and saved the dataset over itself without the columns in the vars variable. 

Gender: Male is 0, Female is 1
```{r echo=FALSE, message = FALSE}
data <- read.csv("SEAS_cleandata.csv")[-63]
data <- subset(data, Gender %in% c("F", "M"))

data$Gender <- as.factor(data$Gender)
levels(data$Gender)<- c( 0,1)
data$Gender <- as.numeric(as.character(data$Gender))
vars <- c('Department', 'Position', 'Tenure','Gender', 'Salary')
data_tree <- data[,(names(data) %in% vars)]
data_tree$Salary <- as.numeric(gsub("[\\$,]", "", data_tree $Salary))

```

### Splitting

We will start off our decision tree by splitting the data into a training and a testing set
```{r, echo=FALSE, include=FALSE, warning=FALSE}
# Split your data into test and train using the caret
x <- createDataPartition(data_tree$Gender,times=1,p = 0.8,list=FALSE)
training_tree <- data_tree[x, -3]
testing_tree <- data_tree[-x, -3]
```

```{r, echo=FALSE, include=FALSE, warning=FALSE}
data_long = data_tree %>% gather(Var, #<- list of predictor variables
                                Value,#<- the values of those predictor variables
                                -Gender) 
data_long_form = ddply(data_long, 
                            .(Var, Value),#<- group by Var and Value, "." 
                            #allows us to call the variables without quoting
                            summarize,  
                            prob_Gender = mean(Gender), #<- probability of being Parent
                            prob_not_Gender = 1 - mean(Gender)) #<- probability of not being Parent
```

### Building the Model

We build our model using the default setting and by using the rpart function. PR.Status is used as the "formula" aka our response variable. We utilize our previously split training dataset and set a cp of 0.01 as it is our default.

```{r, echo=FALSE, include=FALSE, warning=FALSE}
set.seed(2702)
data_gini = rpart(Gender~.,  #<- formula, response variable ~ predictors
                           #   "." means "use all other variables in data"
                            method = "class",#<- specify method, use "class" for tree
                            parms = list(split = "gini"),#<- method for choosing tree split
                            data = training_tree,#<- data used
                            control = rpart.control(cp=.01))
```


### Decision Tree{.tabset}
#### Visually 

First, we can take a look to see the order of importance of the employee's other factors that we can use to guess gender with.
```{r, echo=FALSE}
rpart.plot(data_gini, type =5, extra = 101)
```

Most important is the department that the employee is.

#### Variable Importance

```{r, echo=FALSE}
kable(data_gini$variable.importance) 
```



### CP Chart {.tabset}
#### Plot 
```{r, echo=FALSE}
plotcp(data_gini)
```

#### Table
```{r, echo=FALSE}
cptable_ex <- as_tibble(data_gini$cptable)
kable(cptable_ex)
```
Next, we produce a "elbow chart" for various cp values and their associated relative errors. The dashed line represents the highest cross-validated error minus the minimum cross-validated error, plus the standard deviation of the error at that tree. A reasonable choice of cp for pruning is  the leftmost value because this is where the mean is less than the horizontal line. 

The optimal number of splits is 3 as shown in the cptable_ex because this is where the chart first dips below the mean line. Any more splitting increases the x-val relative error. Furthermore, we can also see in the cptable that this has a low relative error, okay xerror, and a decent xstd

### Prediction

Next, we use the predict function to predict the target variable.
```{r, echo=FALSE}
tree_predict = predict(data_gini,testing_tree, type= "class")
```



### Confusion Matrix {.tabset}
#### Hit and Detection Rate
```{r, echo=FALSE, include=FALSE, warning=FALSE}
confusionMatrix(as.factor(tree_predict), as.factor(testing_tree$Gender), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")
```

#### Best Metrics
```{r, echo=FALSE, include=FALSE, warning=FALSE}
par_conf_matrix<-confusionMatrix(as.factor(tree_predict), as.factor(testing_tree$Gender), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")
```

```{r, echo=FALSE, include=FALSE, warning=FALSE}
par_error_rate = (par_conf_matrix$table[1,2]+par_conf_matrix$table[2,1]) / (par_conf_matrix$table[1,2]+par_conf_matrix$table[2,1]+par_conf_matrix$table[1,1]+par_conf_matrix$table[2,2])

par_error_rate
```


```{r, echo=FALSE, include=FALSE, warning=FALSE}
true_pos_rate = par_conf_matrix$table[2,2]/(par_conf_matrix$table[1,2]+par_conf_matrix$table[2,1]+par_conf_matrix$table[1,1]+par_conf_matrix$table[2,2])
true_pos_rate 
```


## Conclusion



